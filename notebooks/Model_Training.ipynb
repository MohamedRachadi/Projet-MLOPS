{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette classe gère l'entraînement des modèles et le calcul des métriques de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "    Classe pour entraîner des modèles et calculer leurs métriques de performance.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def train_model(model, X_train, y_train, X_test, y_test):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        return model, rmse, mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette classe configure et gère le suivi des expériences dans MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MLFlowLogger:\n",
    "    \"\"\"\n",
    "    Classe pour gérer le suivi des expériences dans MLflow.\n",
    "    \"\"\"\n",
    "    experiment_name: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "    def log_experiment(self, model_name, model, X_train, y_train, X_test, y_test, hyperparameters=None):\n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            mlflow.log_param(\"model_name\", model_name)\n",
    "            if hyperparameters:\n",
    "                mlflow.log_params(hyperparameters)\n",
    "\n",
    "            trainer = ModelTrainer()\n",
    "            trained_model, rmse, mae, r2 = trainer.train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "            # Log des métriques\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "            mlflow.log_metric(\"mae\", mae)\n",
    "            mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "            # Exemple d'entrée\n",
    "            input_example = pd.DataFrame({\n",
    "                \"MedInc\": [1.0], \"HouseAge\": [15.0], \"AveRooms\": [6.0],\n",
    "                \"AveBedrms\": [2.0], \"Population\": [300.0], \"AveOccup\": [4.0],\n",
    "                \"Latitude\": [37.0], \"Longitude\": [-122.0]\n",
    "            })\n",
    "\n",
    "            # Log du modèle\n",
    "            mlflow.sklearn.log_model(trained_model, \"model\", input_example=input_example)\n",
    "\n",
    "            return trained_model, rmse, mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette classe s'occupe d'optimiser les hyperparamètres des modèles en utilisant une recherche bayésienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelOptimizer:\n",
    "    \"\"\"\n",
    "    Classe pour optimiser les hyperparamètres des modèles avec recherche bayésienne.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def optimize_model(model, param_space, X_train, y_train):\n",
    "        opt = BayesSearchCV(\n",
    "            model,\n",
    "            param_space,\n",
    "            n_iter=20,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=3,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "        opt.fit(X_train, y_train)\n",
    "        return opt.best_estimator_, opt.best_params_, -opt.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette classe compare différents modèles, les optimise, et suit leurs résultats avec MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelComparator:\n",
    "    \"\"\"\n",
    "    Classe pour comparer différents modèles, les optimiser, et suivre les résultats.\n",
    "    \"\"\"\n",
    "    logger: MLFlowLogger\n",
    "\n",
    "    def compare_models(self, X_train, y_train, X_test, y_test):\n",
    "        models = {\n",
    "            \"Linear Regression\": LinearRegression(),\n",
    "            \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "            \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
    "        }\n",
    "\n",
    "        param_spaces = {\n",
    "            \"Linear Regression\": {\n",
    "                'fit_intercept': [True, False]\n",
    "            },\n",
    "            \"Random Forest\": {\n",
    "                'n_estimators': Integer(50, 150),\n",
    "                'max_depth': Integer(5, 10),\n",
    "                'min_samples_split': Integer(2, 10),\n",
    "                'min_samples_leaf': Integer(1, 5)\n",
    "            },\n",
    "            \"Gradient Boosting\": {\n",
    "                'n_estimators': Integer(50, 150),\n",
    "                'learning_rate': Real(0.001, 0.01, prior='uniform'),\n",
    "                'max_depth': Integer(3, 8),\n",
    "                'min_samples_split': Integer(2, 10),\n",
    "                'min_samples_leaf': Integer(1, 5)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        best_model = None\n",
    "        best_rmse = float('inf')\n",
    "        best_model_name = \"\"\n",
    "        best_model_params = {}\n",
    "        final_best_model = None  # Initialize it here\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            print(f\"\\nOptimizing {model_name}...\")\n",
    "\n",
    "            optimizer = ModelOptimizer()\n",
    "            best_model, best_params, best_score = optimizer.optimize_model(model, param_spaces[model_name], X_train, y_train)\n",
    "\n",
    "            print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "            print(f\"Best score (RMSE) for {model_name}: {best_score}\")\n",
    "\n",
    "            self.logger.log_experiment(model_name, best_model, X_train, y_train, X_test, y_test, hyperparameters=best_params)\n",
    "\n",
    "            if best_score < best_rmse:\n",
    "                best_rmse = best_score\n",
    "                best_model_name = model_name\n",
    "                final_best_model = best_model  # Update the final_best_model\n",
    "                best_model_params = best_params  # Update the best_model_params\n",
    "\n",
    "        print(f\"Best model: {best_model_name} with RMSE: {best_rmse}\")\n",
    "        print(f\"\\n \\n Best model: {final_best_model} with RMSE: {best_model_params} \\n \\n \")\n",
    "        return final_best_model, best_model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette classe permet d'enregistrer le meilleur modèle dans le registre MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BestModelRegistry:\n",
    "    \"\"\"\n",
    "    Classe pour enregistrer le meilleur modèle dans le registre MLflow.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def register_best_model(best_model, best_params):\n",
    "        model_name = f\"California_Housing_Best_Model_{best_model.__class__.__name__}\"\n",
    "        input_example = pd.DataFrame({\n",
    "            \"MedInc\": [1.0], \"HouseAge\": [15.0], \"AveRooms\": [6.0],\n",
    "            \"AveBedrms\": [2.0], \"Population\": [300.0], \"AveOccup\": [4.0],\n",
    "            \"Latitude\": [37.0], \"Longitude\": [-122.0]\n",
    "        })\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"Best Model Registration: {model_name}\"):\n",
    "            mlflow.sklearn.log_model(\n",
    "                sk_model=best_model,\n",
    "                artifact_path=\"best_model\",\n",
    "                registered_model_name=model_name,\n",
    "                input_example=input_example\n",
    "            )\n",
    "            mlflow.log_params(best_params)\n",
    "            print(f\"Le meilleur modèle a été enregistré avec le nom '{model_name}' et ses hyperparamètres.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiler et voir les résultats dans MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données sont chargées.\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/Std data\"\n",
    "\n",
    "X_train = pd.read_csv(f\"{data_path}/X_train.csv\")\n",
    "X_test = pd.read_csv(f\"{data_path}/X_test.csv\")\n",
    "y_train = pd.read_csv(f\"{data_path}/y_train.csv\").squeeze()  \n",
    "y_test = pd.read_csv(f\"{data_path}/y_test.csv\").squeeze()\n",
    "\n",
    "print(\"Les données sont chargées.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les classes sont initialisées.\n"
     ]
    }
   ],
   "source": [
    "# Initialiser le logger MLflow\n",
    "logger = MLFlowLogger(experiment_name=\"California Housing Project\")\n",
    "\n",
    "# Initialiser le comparateur de modèles\n",
    "comparator = ModelComparator(logger=logger)\n",
    "\n",
    "print(\"Les classes sont initialisées.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing Linear Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [True] before, using random point [True]\n",
      "  warnings.warn(\n",
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [True] before, using random point [False]\n",
      "  warnings.warn(\n",
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [True] before, using random point [True]\n",
      "  warnings.warn(\n",
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [True] before, using random point [True]\n",
      "  warnings.warn(\n",
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [True] before, using random point [False]\n",
      "  warnings.warn(\n",
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [True] before, using random point [False]\n",
      "  warnings.warn(\n",
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [True] before, using random point [False]\n",
      "  warnings.warn(\n",
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [True] before, using random point [True]\n",
      "  warnings.warn(\n",
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [True] before, using random point [True]\n",
      "  warnings.warn(\n",
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [True] before, using random point [False]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Linear Regression: OrderedDict([('fit_intercept', True)])\n",
      "Best score (RMSE) for Linear Regression: 0.7014875053735343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 1362.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Linear Regression at: http://127.0.0.1:5000/#/experiments/616656509998415542/runs/e81c6a073a284d4291a211e0f952754e\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/616656509998415542\n",
      "\n",
      "Optimizing Random Forest...\n",
      "Best parameters for Random Forest: OrderedDict([('max_depth', 10), ('min_samples_leaf', 4), ('min_samples_split', 2), ('n_estimators', 150)])\n",
      "Best score (RMSE) for Random Forest: 0.2964069726506357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 1145.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Random Forest at: http://127.0.0.1:5000/#/experiments/616656509998415542/runs/b165759eae29478081832820d90400bb\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/616656509998415542\n",
      "\n",
      "Optimizing Gradient Boosting...\n",
      "Best parameters for Gradient Boosting: OrderedDict([('learning_rate', 0.01), ('max_depth', 8), ('min_samples_leaf', 5), ('min_samples_split', 10), ('n_estimators', 150)])\n",
      "Best score (RMSE) for Gradient Boosting: 0.3558230178694675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrach\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 501.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Gradient Boosting at: http://127.0.0.1:5000/#/experiments/616656509998415542/runs/5988cbcfecad4a06aa636b08d92d602f\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/616656509998415542\n",
      "Best model: Random Forest with RMSE: 0.2964069726506357\n",
      "\n",
      " \n",
      " Best model: RandomForestRegressor(max_depth=10, min_samples_leaf=4, n_estimators=150,\n",
      "                      random_state=42) with RMSE: OrderedDict([('max_depth', 10), ('min_samples_leaf', 4), ('min_samples_split', 2), ('n_estimators', 150)]) \n",
      " \n",
      " \n",
      "Comparaison des modèles terminée.\n"
     ]
    }
   ],
   "source": [
    "# Comparer les modèles\n",
    "best_model, best_params = comparator.compare_models(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"Comparaison des modèles terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 570.83it/s] \n",
      "Registered model 'California_Housing_Best_Model_RandomForestRegressor' already exists. Creating a new version of this model...\n",
      "2025/01/11 12:45:42 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: California_Housing_Best_Model_RandomForestRegressor, version 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le meilleur modèle a été enregistré avec le nom 'California_Housing_Best_Model_RandomForestRegressor' et ses hyperparamètres.\n",
      "🏃 View run Best Model Registration: California_Housing_Best_Model_RandomForestRegressor at: http://127.0.0.1:5000/#/experiments/616656509998415542/runs/5416af88d0554ff3bb07d21a26631903\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/616656509998415542\n",
      "Le meilleur modèle a été enregistré avec succès.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '4' of model 'California_Housing_Best_Model_RandomForestRegressor'.\n"
     ]
    }
   ],
   "source": [
    "# Enregistrer le meilleur modèle\n",
    "registry = BestModelRegistry()\n",
    "registry.register_best_model(best_model, best_params)\n",
    "\n",
    "print(\"Le meilleur modèle a été enregistré avec succès.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
